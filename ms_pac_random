#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 20 21:09:59 2018

@author: bruceokallau
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Jan 27 22:54:54 2018

@author: bruceokallau
"""
import time
import numpy as np
import gym
import matplotlib.pyplot as plt


start_time = time.time()

env = gym.make('MsPacman-ram-v0')
''' ms pacman ram gives us the 128 byte RAM of the Atari game, possible actions range from 0-9?'''

total_episodes = 4000 #Set total number of episodes to train agent on.
max_ep = 999

i = 0
total_reward = []
total_lenght = []
plot_reward = []

        
while i < total_episodes:
    s = env.reset()
    env.render()
    running_reward = 0
    ep_history = []
    for j in range(max_ep):            
        a = env.action_space.sample()

        s1,r,d,l = env.step(a) #Get our reward for taking an action
        env.render()
        ep_history.append([s,a,r,s1,l])
        s = s1
        running_reward += r
        if d == True:
            total_reward.append(running_reward)
            total_lenght.append(j)
            break

        
            #Update our running tally of scores.
    if i % 50 == 0:
        print(np.mean(total_reward[-50:]))
        plot_reward.append(np.mean(total_reward[-50:]))
    i += 1

print(np.mean(total_reward[-50:]))
print("%d episodes %f seconds - mean total reward %f" % (total_episodes, (time.time() - start_time) , (np.mean(total_reward))))

plt.plot(plot_reward)

#4000 episodes 13686.985785 seconds - mean total reward 215.903584
#1000 episodes 9592.863213 seconds - mean total reward 218.010101
# 500 episodes 785.527534 seconds - mean total reward 210.121457
# 100 ep - 125.149722 seconds - mean total reward - 211.326530612
# 10 ep - 43 seconds - mean total reward = 194

# no matter how many episodes run mean total reward stays around 215
